services:
  postgres:
    image: postgres:16
    # load credentials from .env in the same directory as this compose file
    env_file: .env
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: warehouse
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d
    ports: ["5432:5432"]

  adminer:
    image: adminer
    ports: ["8081:8080"]
    depends_on: [postgres]

  airflow:
    image: apache/airflow:3.1.0
    # load Airflow / Postgres creds from .env (this file is located in `./airflow/.env`)
    env_file: .env
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/warehouse
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-admin}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-admin}
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./data/product-database:/opt/airflow/data/product-database
      # requirements are installed into the image at build time via Dockerfile
    command: >
      bash -lc "airflow dag-processor & airflow api-server & airflow scheduler"
    ports: ["8080:8080"]
    depends_on: [postgres]

volumes:
  pgdata:
